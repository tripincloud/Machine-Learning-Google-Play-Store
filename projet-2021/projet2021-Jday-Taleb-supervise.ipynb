{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (LU3IN0226) -- 2020-2021\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Vincent Guigue, Christophe Marsala, Edoardo Sarti, Olivier Schwander.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation du notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\">**[Q]**</font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JDAY Achraf\n",
    "\n",
    "TALEB Rida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Renommer ce fichier ipython**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>projet-2021</tt> et rajouter à la suite de <tt>projet-2021</tt> les noms des membres du binômes séparés par un tiret.\n",
    "\n",
    "Par exemple, pour le binôme Luke Skywalker et Han Solo, le nom de fichier devient `projet2021-Skywalker-Solo`\n",
    "\n",
    "Penser à sauvegarder fréquemment le fichier en cours de travail :\n",
    "- soit en cliquant sur l'icône \"disquette\"\n",
    "- soit par la combinaison de touches [Ctrl]-S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données\n",
    "\n",
    "Les données vous sont fournies sur le moodle. \n",
    "Ces données sont fournies sur Kaggle, ce sont les données *Google Play Store Apps* accessibles à l'adresse https://www.kaggle.com/lava18/google-play-store-apps.\n",
    "\n",
    "Il est indispensable de lire en détail la page Kaggle pour comprendre à quoi ces données correspondent.\n",
    "\n",
    "Le compte-rendu a fournir le jour de la dernière séance de TDTME de votre groupe doit comporter:\n",
    "- un fichier PDF qui correspond à un poster sur lequel sont expliqués les différents problèmes traités, la façon dont ils ont été traités, et les résultats obtenus.\n",
    "- un notebook par problème traité, vous pouvez traiter autant de problème que vous le souhaitez. Le problème étudié doit être décrit précisément et vous devez impérativement suivre le format ci-dessous.\n",
    "\n",
    "Bien entendu, le tout sera mis dans un fichier archive (tar.gz ou zip exclusivement) et déposé sur le site Moodle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format à suivre:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Partie 1 - Description du problème"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilisation et analyse d'une base de données de reviews numérique sur les applications mobile du Google PlayStore afin de prédire si l'application réussira ou non. Au premier lieu l'application réussi si elle a un nombre d'installations très élevé ( >100000), après nous modifions cette contrainte pour que ca soit un problème multiclasses dans les cas qui suivent.\n",
    "#### Cette problèmatique est interessante surtout pour ceux qui souhaitent développer une app pour le PlayStore mais veulent vérifier si elle sera un succés avant en se basant sur ses caractéristiques ce qui permettra au développeur d'avoir un pre-insight sur le développement de son app et une longueur d'avance sur ses concurrents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 - Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nous utilisons des modèles d'apprentissage supervisé que nous avons codé par nous meme, le Perceptron, le ADALINE Analytique, le MultiOOA et finalement les arbres de décisions numérique, tout en changont de paramètres dans plusieurs cas en split ainsi que en cross-validation strat après normalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 - Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies standards:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as classif\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LECTURE DE L'ENSEMBLE DE DONNÉES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data=pd.read_csv('GoogleApps/googleplaystore.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NETTOYAGE DE L'ENSEMBLE DE DONNÉES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L'ensemble de données aura des valeurs redondantes comme NaN, ou certaines colonnes n'auront pas de valeur du tout, certaines colonnes auront des valeurs sans rapport, certaines auront des caractères spéciaux qui ne peuvent pas être introduits dans notre modèle d'apprentissage automatique. Ces incohérences seront donc résolues dans cette section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déplaçons-nous de gauche à droite dans les colonnes de l'ensemble de données, nous commençons par la colonne \"RATING\", et nous nous déplaçons jusqu'à la colonne \"PRICE\", puisque ce sont des colonnes numériques et des caractéristiques nécessaires pour notre modèle. Nous allons effectuer le processus suivant sur chacune de ces colonnes :\n",
    "#### 1)- Vérification de toutes les valeurs uniques dans la colonne.\n",
    "#### 2)- S'il y a des valeurs uniques non liées qui ne sont pas significatives, elles seront remplacées.\n",
    "#### 3)- La vérification des valeurs nulles est effectuée sur chaque colonne numérique, si des entrées nulles sont trouvées, elles sont remplacées par les valeurs moyennes.\n",
    "#### 4)- Les valeurs dans les colonnes contiennent certains caractères spéciaux, qui doivent être supprimés afin d'effectuer des agrégations, ils seront donc supprimés comme \"+\" et \",\" dans la colonne Installs, \"M\", \"Varies with Device\" et \"k\" dans la colonne Size etc.\n",
    "#### 5)- Les colonnes qui sont de type objet seront converties en leurs équivalents numériques pour l'analyse et les tendances.\n",
    "#### 6)- Un filtrage final sera effectué pour s'assurer qu'il n'y a aucune incohérence dans aucune colonne qui pourrait affecter la performance de notre modèle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage de la colonne \"RATING\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérifier s'il y a des valeurs nulles dans la colonne Ratings.\n",
    "nullcheck_ratings=pd.isnull(Application_data[\"Rating\"])\n",
    "Application_data[nullcheck_ratings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remplacer les valeurs NaN par la valeur moyenne de l'évaluation\n",
    "Application_data[\"Rating\"].fillna(value=Application_data[\"Rating\"].mean(),inplace=True)\n",
    "Application_data[\"Rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vérifiant les valeurs uniques dans la colonne Classement, nous constatons qu'il y a une valeur incohérente de 19.\n",
    "Application_data[\"Rating\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer la valeur incohérente par la valeur moyenne des évaluations\n",
    "Application_data[\"Rating\"].replace(19.,4.1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aucun caractère spécial n'a été trouvé dans la colonne des évaluations, l'étape 4 n'est donc pas nécessaire. De plus, le type de données de la colonne ratings est déjà float, donc pas besoin de conversion. Donc maintenant notre colonne Rating est prête pour l'analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage de la colonne \"REVIEWS\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vérifiant les valeurs uniques de la colonne nombre de critiques, nous constatons qu'il n'y a pas de valeurs non liées.\n",
    "len(Application_data[\"Reviews\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vérifiant les valeurs nulles de la colonne nombre de critiques, nous constatons qu'il n'y a pas de valeurs nulles.\n",
    "nullcheck_reviews=pd.isnull(Application_data[\"Reviews\"])\n",
    "Application_data[nullcheck_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vérifiant les caractères spéciaux qui pourraient empêcher la conversion numérique, 3.0M est remplacé par sa valeur réelle pour rendre les données cohérentes.\n",
    "Application_data[\"Reviews\"].replace(\"3.0M\",\"3000000\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enfin, nous convertissons le type de données de la colonne Reviews du type Object (String) au type Numeric (float ou int).\n",
    "Application_data[\"Reviews\"]=pd.to_numeric(Application_data[\"Reviews\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toutes les étapes ont été réalisées pour la colonne de reviews et elle est également prête pour l'analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage de la colonne \"SIZE\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vérifiant les valeurs uniques de la colonne Size, on observe qu'elle a des valeurs accompagnées de M,k et \"Varies with device\".\n",
    "Application_data[\"Size\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer le champ \"Varies with device\" par des entrées NaN, afin de pouvoir les remplacer ultérieurement par des valeurs moyennes.\n",
    "Application_data['Size'].replace('Varies with device', np.nan, inplace = True )\n",
    "Application_data['Size'].replace('1,000+', np.nan, inplace = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les valeurs nulles que nous allons trouver, puisque dans la ligne ci-dessus nous avons ajouté quelques valeurs nulles.\n",
    "nullcheck_size=pd.isnull(Application_data[\"Size\"])\n",
    "Application_data[nullcheck_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nous devons maintenant remplacer les valeurs NaN par la taille moyenne de toutes les applications, mais nous ne pouvons pas calculer la moyenne car notre colonne est de type Object String, nous devons donc la convertir en type numérique. De plus, nous devons supprimer \"M\", \"k\" des valeurs de la colonne, car nous ne pouvons pas les convertir en numérique sans manipuler ces symboles spéciaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data.Size = (Application_data.Size.replace(r'[kM]+$','', regex=True).astype(float) *\n",
    "                         Application_data.Size.str.extract(r'[\\d\\.]+([kM]+)', expand=False).fillna(1).replace(['k','M'], [10**3, 10**6]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enfin, remplacer les valeurs NaN par la valeur moyenne.\n",
    "Application_data[\"Size\"].fillna(value=\"21516530\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Après avoir supprimé les caractères spéciaux, convertissons-le en type de données numériques pour trouver la valeur moyenne.\n",
    "Application_data[\"Size\"]=pd.to_numeric(Application_data[\"Size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ici, nous avons terminé le nettoyage de la colonne Taille en suivant les 6 étapes qui étaient requises, puisque cette colonne était très peu nettoyée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Le nettoyage de la colonne \"INSTALL\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vérifiant les valeurs uniques de la colonne Installs, nous observons qu'il existe un type appelé \"free\", qui est incohérent et non numérique, il doit donc être remplacé.\n",
    "Application_data[\"Installs\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nous devons supprimer le mot \"gratuit\" du nombre moyen d'installations des applications, mais pour calculer la moyenne, nous devons supprimer les signes \"+\" et \",\" des valeurs. Après les avoir supprimés, nous devrons les convertir en type numérique, puis nous pourrons calculer la moyenne et enfin substituer la valeur moyenne à la place de \"Free\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression du symbole \"+\" pour rendre la colonne numérique.\n",
    "Application_data[\"Installs\"]=Application_data[\"Installs\"].map(lambda x: x.rstrip('+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlever le \",\" des chiffres pour faciliter la tâche.\n",
    "Application_data[\"Installs\"]=Application_data[\"Installs\"].str.replace(\",\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aucune entrée nulle n'a été trouvée dans cette colonne.\n",
    "nullcheck_installs=pd.isnull(Application_data[\"Installs\"])\n",
    "Application_data[nullcheck_installs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer la valeur incohérente de l'étiquette par la valeur moyenne de la colonne.\n",
    "Application_data[\"Installs\"].replace(\"Free\",\"15462910\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir le type de données en type numérique pour l'analyse\n",
    "Application_data[\"Installs\"]=pd.to_numeric(Application_data[\"Installs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De cette façon, nous avons rendu notre colonne Installs prête pour l'analyse en suivant à nouveau les 6 étapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage de la colonne \"TYPE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vérifiant les valeurs uniques, nous avons trouvé nan et 0 qui doivent être remplacés par Free.\n",
    "Application_data[\"Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement de 0 par Free\n",
    "Application_data[\"Type\"].replace(\"0\",\"Free\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplir les valeurs manquantes avec Free, puisque la plupart des applications sont gratuites sur Google play.\n",
    "Application_data[\"Type\"].fillna(value=\"Free\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter les colonnes fictives pour cela, afin qu'elles puissent contribuer à notre modèle.\n",
    "dummy_type=pd.get_dummies(Application_data[\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concaténation des colonnes fictives avec le cadre de données principal.\n",
    "Application_data=pd.concat([Application_data,dummy_type],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalement, on laisse tomber la colonne de type.\n",
    "Application_data.drop([\"Type\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De cette façon, nous avons supprimé la colonne catégorique Type, utilisé des colonnes fictives pour rendre notre espace de caractéristiques plus précis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage de la colonne \"PRICE\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vérifiant les valeurs uniques, nous constatons que \"Everyone\" est une valeur incohérente qui doit être supprimée.\n",
    "Application_data[\"Price\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ici, pour obtenir la moyenne des valeurs, le type de données de la colonne doit être numérique et pour cela, nous devons supprimer le symbole du dollar des valeurs et abandonner la ligne de tout le monde, car elle contient des données redondantes qui compromettront les performances de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression du symbole du dollar\n",
    "Application_data[\"Price\"]=Application_data[\"Price\"].map(lambda x: x.lstrip('$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression de la valeur de la ligne non essentielle.\n",
    "Application_data.drop(Application_data[Application_data[\"Price\"] == \"Everyone\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vérifiant qu'il n'y a pas de valeurs nulles trouvées\n",
    "nullcheck_Prices=pd.isnull(Application_data[\"Price\"])\n",
    "Application_data[nullcheck_Prices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enfin convertir en type numérique pour l'analyse\n",
    "Application_data[\"Price\"]=pd.to_numeric(Application_data[\"Price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nous avons nettoyé la colonne Prix en suivant les 6 étapes selon les besoins, maintenant cette colonne est prête pour l'analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage de la colonne \"CATEGORY\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vérifiant les valeurs uniques, nous avons trouvé \n",
    "Application_data[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data[\"Category\"].replace(\"1.9\",\"MISCELLANEOUS\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification des valeurs nulles, aucune valeur nulle n'a été trouvée pour cette colonne.\n",
    "nullcheck=pd.isnull(Application_data[\"Category\"])\n",
    "Application_data[nullcheck]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour cette colonne, nous allons procéder à l'encodage des étiquettes et non des mannequins, car en faisant des mannequins, nous ajouterons trop de colonnes supplémentaires à notre matrice de caractéristiques, ce qui n'est pas nécessaire. L'encodage des étiquettes est donc effectué en fournissant des valeurs numériques à chaque catégorie d'application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de la bibliothèque requise\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation de l'encodeur\n",
    "labelencoder2 = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encodage de la colonne Category en utilisant scikit learn\n",
    "Application_data['Categories_encoded'] = labelencoder2.fit_transform(Application_data['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enfin, on laisse tomber la colonne type, puisqu'elle est déjà fractionnée.\n",
    "Application_data.drop([\"Category\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage de la colonne \"CONTENT RATING\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour cette colonne catégorielle également, nous effectuons l'encodage des étiquettes comme nous l'avons fait pour la colonne Catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data[\"Content Rating\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullcheck_contentrating=pd.isnull(Application_data[\"Content Rating\"])\n",
    "Application_data[nullcheck_contentrating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data['Content_Rating_encoded'] = labelencoder.fit_transform(Application_data['Content Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data.drop([\"Content Rating\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les types de données des colonnes pour s'assurer que nous avons réussi à rassembler toutes les colonnes numériques.\n",
    "Application_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver la moyenne de toutes les colonnes numériques\n",
    "Application_data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSE DES DONNÉES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vous trouverez ci-dessous une analyse complète des diverses relations entre les caractéristiques de nos données. Cette analyse est nécessaire pour que nous puissions comprendre quelles sont les caractéristiques qui joueront un rôle important dans la prédiction du nombre d'installations d'une application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(Application_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ici, un diagramme de paires est montré entre toutes les colonnes numériques des données. Cela donne un haut niveau d'intuition entre les relations entre les différentes caractéristiques. Tout d'abord, des histogrammes seront dessinés pour toutes les colonnes numériques afin de connaître leur nombre et leur distribution. Plotly est utilisé ici pour les représentations graphiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorassigned=Application_data[\"Rating\"]\n",
    "fig = px.histogram(Application_data, x=\"Rating\", marginal=\"rug\",\n",
    "                   hover_data=Application_data.columns,nbins=30,color=colorassigned)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Le graphique ci-dessus est un histogramme, qui montre la distribution des évaluations de diverses applications androïdes. L'histogramme est divisé en couleurs en fonction des valeurs de l'évaluation. L'échelle de couleurs est indiquée sur le côté droit. Le nombre de notes 4.1 est maximal (1474) comme on peut le constater en survolant le graphique. De plus, le nombre de notes augmente uniformément de 3,4 (128) à 4,1 (1474), puis augmente et diminue à nouveau. Cela signifie que la plupart des applications sur Google Play ont des notes comprises entre 4 et 4,5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(Application_data, x=\"Reviews\", marginal=\"rug\",\n",
    "                   hover_data=Application_data.columns,nbins=30)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voici un histogramme qui montre la distribution du nombre d'avis pour chaque application. Il est clairement visible que 90% des applications sur Google Play Store ont moins de 5 millions d'avis. 138 applications ont des avis entre 5 et 10 millions. Seules 47 applications androïdes ont des avis entre 10 et 15 millions. La majorité des applications ont donc moins de 5 millions d'avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorassigned=Application_data[\"Size\"]\n",
    "fig = px.histogram(Application_data, x=\"Size\", marginal=\"rug\",\n",
    "                   hover_data=Application_data.columns,nbins=30,color=colorassigned)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Le graphique ci-dessus est un histogramme, qui montre la distribution de la taille de diverses applications androïdes. On peut observer que la plupart des applications ont une taille inférieure, puisque lorsque la taille augmente sur l'axe des x, les barres deviennent de plus en plus courtes, ce qui signifie que le nombre de ces types d'applications diminue. Nous avons donc plus d'applications sur Google playstore qui sont de petite taille que de grandes applications. La plupart des applications ont une taille d'environ 21,5 Mo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorassigned=Application_data[\"Installs\"]\n",
    "fig = px.histogram(Application_data, x=\"Installs\", marginal=\"rug\",\n",
    "                   hover_data=Application_data.columns,nbins=30,color=colorassigned)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Le graphique ci-dessus montre le nombre d'installations d'applications androïdes. On peut observer que la majorité des applications ont moins de 10 millions d'installations. De plus, il n'y a que 58 applications qui ont plus d'un milliard d'installations sur Google play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorassigned=Application_data[\"Price\"]\n",
    "fig = px.histogram(Application_data, x=\"Price\", marginal=\"rug\",\n",
    "                   hover_data=Application_data.columns,nbins=30,color=colorassigned)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cet histogramme montre la répartition des prix de diverses applications androïdes sur Google play. La majorité des applications sont gratuites. Il y a 12 applications androïdes qui sont les plus chères, coûtant 400 dollars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nous avons ainsi terminé l'analyse individuelle de toutes les colonnes numériques de notre ensemble de données. Maintenant, nous allons trouver la relation entre chaque colonne pour l'analyser en profondeur. L'étape suivante est la suivante :\n",
    "### 1)- Calculer la valeur de corrélation et dessiner une carte thermique pour connaître la corrélation entre les différentes colonnes.\n",
    "### 2)- Une fois que nous avons trouvé la corrélation, nous savons quelles colonnes s'influencent les unes les autres, puis nous commençons à tracer les colonnes par paire en fonction de leurs valeurs de corrélation. Si la corrélation est négative ou très faible, il n'y a aucun intérêt à tracer ces colonnes.\n",
    "### 3)- Après le tracé, nous ajustons une ligne de régression linéaire à nos points de données. Plus la valeur de corrélation est élevée, meilleure est la ligne d'ajustement que nous obtenons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Correlation and plotting the heatmap to know the relations.\n",
    "cors=Application_data.corr()\n",
    "fig = px.imshow(cors,labels=dict(color=\"Pearson Correlation\"), x=['Rating', 'Reviews', 'Size', 'Installs', 'Price','Paid','Free','Content_Rating_encoded','Categories_encoded'],\n",
    "                y=['Rating', 'Reviews', 'Size','Installs','Price','Paid','Free','Content_Rating_encoded','Categories_encoded'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les conclusions suivantes peuvent être tirées de cette carte thermique :\n",
    "### VALEUR DE CORRÉLATION CARACTÉRISTIQUES IMPLIQUÉES VERDICT\n",
    "\n",
    "-0,020 Prix par rapport au classement Aucune corrélation\n",
    "\n",
    "### -0,009 Prix par rapport aux avis Pas de corrélation\n",
    "\n",
    "### -0.022 Prix vs Taille Pas de corrélation\n",
    "\n",
    "### 0,011 Prix par rapport aux installations Pas de corrélation\n",
    "\n",
    "### 0,051 Installations par rapport au classement Aucune corrélation\n",
    "\n",
    "### 0,643 Installes vs critiques Grande corrélation\n",
    "\n",
    "### 0,082 Installes vs Taille Pas de corrélation\n",
    "\n",
    "### -0.011 Installes vs Prix Pas de corrélation\n",
    "\n",
    "### 0,074 Taille par rapport au classement Aucune corrélation\n",
    "\n",
    "### 0,128 Taille par rapport aux évaluations Corrélation très faible\n",
    "\n",
    "### 0,082 Taille par rapport aux installations Aucune corrélation\n",
    "\n",
    "### -0.022 Taille vs Prix Pas de corrélation\n",
    "\n",
    "### 0.067 Critiques vs Classement Pas de corrélation\n",
    "\n",
    "\n",
    "\n",
    "## Nous ne tracerons que les relations dont la valeur de corrélation est supérieure à 0,1, les autres n'ayant aucune corrélation, le tracé ne sera pas fructueux. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer un diagramme de dispersion avec une ligne d'ajustement entre les installations et les évaluations, ces deux éléments ont la corrélation la plus élevée entre eux.\n",
    "from scipy.stats import pearsonr \n",
    "corryu,_ =pearsonr(Application_data[\"Installs\"],Application_data[\"Reviews\"])\n",
    "colorassigned=Application_data[\"Reviews\"]\n",
    "fig = px.scatter(Application_data, x=\"Installs\", y=\"Reviews\",trendline=\"ols\",color=colorassigned)\n",
    "fig.show()\n",
    "print(\"Pearson Correlation: %.3f\" % corryu)\n",
    "print(\"P-value: %.8f\" % _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On observe que nous avons un bon ajustement aux points de données, puisque la corrélation entre ces 2 colonnes est significative. Comme on peut le voir, le nombre de critiques augmente avec le nombre d'installations, ce qui est logique, puisque si l'utilisateur a installé l'application, il est le seul à pouvoir donner son avis. Sans l'utilisation d'une application, il est impossible de donner des avis. Si nous obtenons un nouveau point de données, nous pouvons prédire son nombre d'installations sur la base du nombre d'évaluations. En survolant la ligne rouge, on peut voir l'équation de la ligne droite. En survolant chaque point de données, on obtient le nombre d'installations et d'évaluations à ce point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer un nuage de points avec une ligne d'ajustement entre le classement et les critiques, ces deux éléments ont une corrélation très faible entre eux. \n",
    "from scipy.stats import pearsonr \n",
    "corryu,_ =pearsonr(Application_data[\"Rating\"],Application_data[\"Reviews\"])\n",
    "colorassigned=Application_data[\"Reviews\"]\n",
    "fig = px.scatter(Application_data, x=\"Rating\", y=\"Reviews\",trendline=\"ols\",color=colorassigned)\n",
    "fig.show()\n",
    "print(\"Pearson Correlation: %.3f\" % corryu)\n",
    "print(\"P-value: %.8f\" % _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comme on peut l'observer sur ce graphique, on constate que les applications qui ont des notes comprises entre 4 et 4,7 ont un nombre maximum d'avis. Cependant, nous ne pouvons pas dire que plus les notes augmentent, plus le nombre d'avis augmente, cela se produit juste pour une plage particulière de 4 à 4,7 où les avis augmentent en même temps que les notes, mais avant 4 et après 4,7, la tendance est différente. On observe qu'après une note de 4,7, le nombre d'avis a diminué, c'est-à-dire que le nombre d'applications ayant reçu un avis a diminué. Les applications ayant 5 étoiles n'ont que 4 commentaires. Cependant, les applications ayant une note inférieure à 4 ont été évaluées par de nombreux utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer un nuage de points avec une ligne d'ajustement entre la taille et les critiques, ces deux éléments ont une corrélation très faible entre eux. \n",
    "from scipy.stats import pearsonr \n",
    "corryu,_ =pearsonr(Application_data[\"Size\"],Application_data[\"Reviews\"])\n",
    "colorassigned=Application_data[\"Reviews\"]\n",
    "fig = px.scatter(Application_data, x=\"Size\", y=\"Reviews\",trendline=\"ols\",color=colorassigned)\n",
    "fig.show()\n",
    "print(\"Pearson Correlation: %.3f\" % corryu)\n",
    "print(\"P-value: %.8f\" % _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Il n'y a pas de tendance générale observée dans ce graphique, car il y a très peu de corrélation observée dans ces deux colonnes. Il y a des applications de 21 Mo qui obtiennent 80 millions d'avis, et il y a des applications de taille plus importante, comme 98 Mo, qui obtiennent 45 millions d'avis. Il n'y a donc pas de tendance observée ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr \n",
    "corryu,_ =pearsonr(Application_data[\"Installs\"],Application_data[\"Categories_encoded\"])\n",
    "colorassigned=Application_data[\"Categories_encoded\"]\n",
    "fig = px.scatter(Application_data, x=\"Installs\", y=\"Categories_encoded\",trendline=\"ols\",color=colorassigned)\n",
    "fig.show()\n",
    "print(\"Pearson Correlation: %.3f\" % corryu)\n",
    "print(\"P-value: %.8f\" % _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 4 - Protocole expérimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas 1: deux labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection et Split des datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Application_data[\"Categories_encoded\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_data[\"Installs\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(df):\n",
    "    x = df['Installs']\n",
    "    if x < 100000:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "Application_data['Label'] = Application_data.apply(lambda df: label(df), axis=1)\n",
    "Application_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa=Application_data[[\"Reviews\",\"Size\",\"Rating\",\"Price\",\"Paid\",\"Free\",\"Categories_encoded\",\"Content_Rating_encoded\"]]\n",
    "ya=Application_data[\"Label\"].values\n",
    "print(Xa)\n",
    "x1=Xa.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "Xa = preprocessing.StandardScaler().fit(Xa).transform(Xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xa_train, Xa_test, ya_train, ya_test = train_test_split(Xa, ya, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xa_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ya_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "perceptron = classif.ClassifierPerceptron(8,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron.train(Xa_train,ya_train)\n",
    "a=perceptron.accuracy(Xa_train,ya_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",ya_train[i],\") --> \",perceptron.predict(Xa_train[i,:]), \"(\",perceptron.score(Xa_train[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=perceptron.accuracy(Xa_test,ya_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",ya_test[i],\") --> \",perceptron.predict(Xa_test[i,:]), \"(\",perceptron.score(Xa_test[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADALINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaline = classif.ClassifierADALINE2(8,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaline.train(Xa_train,ya_train)\n",
    "b=Adaline.accuracy(Xa_train,ya_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",ya_train[i],\") --> \",Adaline.predict(Xa_train[i,:]), \"(\",Adaline.score(Xa_train[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1=Adaline.accuracy(Xa_test,ya_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",ya_test[i],\") --> \",Adaline.predict(Xa_test[i,:]), \"(\",Adaline.score(Xa_test[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noms = [\"Reviews\",\"Size\",\"Rating\",\"Price\",\"Paid\",\"Free\",\"Categories_encoded\",\"Content_Rating_encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbreA = classif.CAD(8, 0, noms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbreA.train(x1,ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gv\n",
    "gr_arbreA = gv.Digraph(format='png')\n",
    "arbreA.affiche(gr_arbreA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbreA1 = classif.CAD(8, 0.25, noms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbreA1.train(x1,ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gv\n",
    "gr_arbreA1 = gv.Digraph(format='png')\n",
    "arbreA1.affiche(gr_arbreA1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas 2: multi labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection et Split des datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(df):\n",
    "    x = df['Installs']\n",
    "    if x < 100000:\n",
    "        return -1\n",
    "    elif x < 10000000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "Application_data['Label'] = Application_data.apply(lambda df: label(df), axis=1)\n",
    "Application_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb=Application_data[[\"Reviews\",\"Size\",\"Rating\",\"Price\",\"Paid\",\"Free\",\"Categories_encoded\",\"Content_Rating_encoded\"]]\n",
    "yb=Application_data[\"Label\"].values\n",
    "print(Xb)\n",
    "x1=Xb.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "Xb = preprocessing.StandardScaler().fit(Xb).transform(Xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(Xb, yb, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "perceptron = classif.ClassifierPerceptron(8,learning_rate)\n",
    "\n",
    "perceptmulti = classif.ClassifierMultiOAA(perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptmulti.train(Xb_train,yb_train)\n",
    "c=perceptmulti.accuracy(Xb_train,yb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",yb_train[i],\") --> \",perceptmulti.predict(Xb_train[i,:]), \"(\",perceptmulti.score(Xb_train[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=perceptmulti.accuracy(Xb_test,yb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",yb_test[i],\") --> \",perceptmulti.predict(Xb_test[i,:]), \"(\",perceptmulti.score(Xb_test[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADALINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaline = classif.ClassifierADALINE2(8,100)\n",
    "AdalineMulti = classif.ClassifierMultiOAA(Adaline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdalineMulti.train(Xb_train,yb_train)\n",
    "d=AdalineMulti.accuracy(Xb_train,yb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",yb_train[i],\") --> \",AdalineMulti.predict(Xb_train[i,:]), \"(\",AdalineMulti.score(Xb_train[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=AdalineMulti.accuracy(Xb_test,yb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",yb_test[i],\") --> \",AdalineMulti.predict(Xb_test[i,:]), \"(\",AdalineMulti.score(Xb_test[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbreB = classif.CAD(8, 0, noms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbreB.train(x1,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gv\n",
    "gr_arbreB = gv.Digraph(format='png')\n",
    "arbreB.affiche(gr_arbreB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbreB1 = classif.CAD(8, 0.25, noms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbreB1.train(x1,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gv\n",
    "gr_arbreB1 = gv.Digraph(format='png')\n",
    "arbreB1.affiche(gr_arbreB1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas 3: Multi labels + less features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection et Split des datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(df):\n",
    "    x = df['Installs']\n",
    "    if x < 100000:\n",
    "        return -1\n",
    "    elif x < 10000000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "Application_data['Label'] = Application_data.apply(lambda df: label(df), axis=1)\n",
    "Application_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc=Application_data[[\"Reviews\",\"Price\",\"Rating\",\"Categories_encoded\"]]\n",
    "yc=Application_data[\"Label\"].values\n",
    "print(Xc)\n",
    "x1 = Xc.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "Xc = preprocessing.StandardScaler().fit(Xc).transform(Xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "perceptron = classif.ClassifierPerceptron(4,learning_rate)\n",
    "\n",
    "perceptmulti = classif.ClassifierMultiOAA(perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptmulti.train(Xc_train,yc_train)\n",
    "e=perceptmulti.accuracy(Xc_train,yc_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",yc_train[i],\") --> \",perceptmulti.predict(Xc_train[i,:]), \"(\",perceptmulti.score(Xc_train[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1=perceptmulti.accuracy(Xc_test,yc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",yc_test[i],\") --> \",perceptmulti.predict(Xc_test[i,:]), \"(\",perceptmulti.score(Xc_test[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADALINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaline = classif.ClassifierADALINE2(4,100)\n",
    "AdalineMulti = classif.ClassifierMultiOAA(Adaline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdalineMulti.train(Xc_train,yc_train)\n",
    "f=AdalineMulti.accuracy(Xc_train,yc_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",yc_train[i],\") --> \",AdalineMulti.predict(Xc_train[i,:]), \"(\",AdalineMulti.score(Xc_train[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=AdalineMulti.accuracy(Xc_test,yc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i+1,\": (\",yc_test[i],\") --> \",AdalineMulti.predict(Xc_test[i,:]), \"(\",AdalineMulti.score(Xc_test[i,:]),\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noms = [\"Reviews\",\"Price\",\"Rating\",\"Categories_encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbreC = classif.CAD(4, 0.0, noms)\n",
    "arbreC.train(x1,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gv\n",
    "gr_arbreC = gv.Digraph(format='png')\n",
    "arbreC.affiche(gr_arbreC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbreC1 = classif.CAD(4, 0.25, noms)\n",
    "arbreC1.train(x1,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gv\n",
    "gr_arbreC1 = gv.Digraph(format='png')\n",
    "arbreC1.affiche(gr_arbreC1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 5 - Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas 1: deux labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données d'apprentissage: \",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données de tests: \",a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Changement du learning rate : on le prend trÃ¨s grand !\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#Â Graine pour les tirages alÃ©atoires :\n",
    "np.random.seed(42)   # supprimer cette ligne une fois la mise au point terminÃ©e\n",
    "\n",
    "niter = 10\n",
    "perf = []\n",
    "\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval_strat(Xa, ya, niter, i)\n",
    "    cl = classif.ClassifierPerceptron(8,learning_rate)\n",
    "    for j in range(0,10):\n",
    "        cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "print(f'\\nRÃ©sultat global:\\tmoyenne= {perf.mean():.3f}\\tÃ©cart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(perf)\n",
    "plt.title(\"Evolution de l'apprentissage\")\n",
    "plt.xlabel('Itération')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Choix du learning rate\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#Â Graine pour les tirages alÃ©atoires :\n",
    "np.random.seed(42)  \n",
    "\n",
    "#Â CrÃ©ation et entraÃ®nement du perceptron sur les donnÃ©es gÃ©nÃ©rÃ©es\n",
    "#Â On utilise la mÃ©morisation de l'historique des poids comme vu en TME 4\n",
    "perceptronV1 = classif.ClassifierPerceptron(8, learning_rate, history=True)\n",
    "\n",
    "# on rÃ©alise 10 appels de train:\n",
    "for i in range(0,10):\n",
    "    perceptronV1.train(Xa_train,ya_train)\n",
    "\n",
    "# rÃ©cupÃ©ration de l'Ã©volution des w au cours de l'apprentissage \n",
    "allw = np.array(perceptronV1.allw) # si allw est sous forme de liste\n",
    "\n",
    "#Â TracÃ© de l'Ã©volution des w:\n",
    "plt.figure()\n",
    "plt.plot(allw[:,0]) #Â premiÃ¨re coordonnÃ©e du vecteur poids: w1\n",
    "plt.plot(allw[:,1]) #Â deuxiÃ¨me coordonnÃ©e du vecteur poids: w2\n",
    "plt.title('Evolution des w au cours des itérations du perceptron')\n",
    "plt.xlabel('iterations')\n",
    "plt.legend(['w1','w2'])\n",
    "\n",
    "#Â Performance de ce classifieur:\n",
    "print(\"Accuracy du perceptron (\", learning_rate,\"): \",perceptronV1.accuracy(Xa_test,ya_test)) \n",
    "print(\"Vecteur de poids final trouvé: \", perceptronV1.getW())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADALINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données d'apprentissage: \",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données de tests: \",b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décisions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_arbreA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_arbreA1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas 2: Multi labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données d'apprentissage: \",c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données de tests: \",c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â On va utiliser un chronomÃ¨tre pour avoir le temps d'exÃ©cution :\n",
    "import timeit\n",
    "#Â Changement du learning rate : on le prend trÃ¨s grand !\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#Â Graine pour les tirages alÃ©atoires :\n",
    "np.random.seed(42)   # supprimer cette ligne une fois la mise au point terminÃ©e\n",
    "\n",
    "niter = 10\n",
    "perf = []\n",
    "\n",
    "tic = timeit.default_timer() # heure de dÃ©part\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval_strat(Xb, yb, niter, i)\n",
    "    cl = classif.ClassifierMultiOAA(classif.ClassifierPerceptron(8,learning_rate))\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "toc = timeit.default_timer() # heure d'arrivÃ©e\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "\n",
    "print(f'\\nTemps mis: --> {toc-tic:.5f} secondes')\n",
    "print(f'RÃ©sultat global:\\tmoyenne= {perf.mean():.3f}\\tÃ©cart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(perf)\n",
    "plt.title(\"Evolution de l'apprentissage\")\n",
    "plt.xlabel('Itération')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADALINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données d'apprentissage: \",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données de tests: \",d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_arbreB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_arbreB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas 3: Multi labels + less features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données d'apprentissage: \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données d'apprentissage: \",e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Changement du learning rate : on le prend trÃ¨s grand !\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#Â Graine pour les tirages alÃ©atoires :\n",
    "np.random.seed(42)   # supprimer cette ligne une fois la mise au point terminÃ©e\n",
    "\n",
    "niter = 10 \n",
    "perf = []\n",
    "\n",
    "tic = timeit.default_timer() # heure de dÃ©part\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = ut.crossval(Xc, yc, niter, i)\n",
    "    cl = classif.ClassifierMultiOAA(classif.ClassifierPerceptron(4,learning_rate))\n",
    "    cl.train(Xapp, Yapp)\n",
    "    perf.append(cl.accuracy(Xtest, Ytest))\n",
    "    print(\"Apprentissage \",i+1,\":\\t\",\" |Yapp|= \",len(Yapp),\" |Ytest|= \",len(Ytest),\"\\tperf= \",perf[-1])\n",
    "toc = timeit.default_timer() # heure d'arrivÃ©e\n",
    "\n",
    "# On transforme la liste en array numpy pour avoir les fonctions statistiques:\n",
    "perf = np.array(perf)\n",
    "\n",
    "print(f'\\nTemps mis: --> {toc-tic:.5f} secondes')\n",
    "print(f'RÃ©sultat global:\\tmoyenne= {perf.mean():.3f}\\tÃ©cart-type= {perf.std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(perf)\n",
    "plt.title(\"Evolution de l'apprentissage\")\n",
    "plt.xlabel('Itération')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADALINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données d'apprentissage: \",f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy sur données de tests: \",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_arbreC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_arbreC1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison entre les Adaline et Perceptron des 3 cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Classifieur': ['Perceptron cas1','Adaline cas1','Perceptron cas2','Adaline cas2','Perceptron cas3','Adaline cas3'], 'Apprentissage Accuracy': [a/100, b/100, c, d, e, f], 'Tests Accuracy': [a1/100, b1/100, c1, d1, e1, f1]}\n",
    "dfdata = pd.DataFrame(data)\n",
    "print(dfdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 6 - Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D'après les statistiques sur les modèles et les résultats nous pouvons clairement constater que le problème binaire marche le meilleur mais pour des raisons de réalisme nous allons regarder que le problème multiclasses et alors seulement le 2eme cas vu que d'après nos experimentations dans le 3eme cas le moins de dimensions/features on a le moins l'accuracy qu'on aura ce qui est logique.\n",
    "#### Dans ce cas, le Perceptron est mieux que le Adaline dans les tests sur les données d'apprentissage ainsi que les données de tests, l'abre de décisions nous montre aussi des résultats logique (Exemple: réussite de l'app s'il y a un très grand nombre de reviews dans une catégorie populaire).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: Résolution de problème réussi, nous avons réussi a prédire a 60% pret le succées d'une application mobile a partir de ses caractéristiques.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
